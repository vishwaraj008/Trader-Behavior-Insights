{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXXdpz8z81Ie",
        "outputId": "34f1b7c6-f01f-4800-8922-ea5f7a1c40b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSVs...\n",
            "Loaded.\n",
            "Trader shape: (211224, 16)\n",
            "Trader cols: ['Account', 'Coin', 'Execution Price', 'Size Tokens', 'Size USD', 'Side', 'Timestamp IST', 'Start Position', 'Direction', 'Closed PnL', 'Transaction Hash', 'Order ID', 'Crossed', 'Fee', 'Trade ID', 'Timestamp']\n",
            "Sentiment shape: (2644, 4)\n",
            "Sentiment cols: ['timestamp', 'value', 'classification', 'date']\n",
            "Sentiment unique classes: ['Fear' 'Extreme Fear' 'Neutral' 'Greed' 'Extreme Greed']\n",
            "After merge, sentiment coverage: 0.9999715941370299\n",
            "Detected cols: coin account closed_pnl size_usd side\n",
            "✅ Saved CSV outputs in csv_files/:\n",
            "- csv_files/volume_by_sentiment.csv\n",
            "- csv_files/win_rate_by_sentiment.csv\n",
            "- csv_files/account_sentiment_profiles.csv\n",
            "- csv_files/top_account_stats.csv\n",
            "- csv_files/merged_trader_sentiment_processed.csv\n",
            "- csv_files/account_stats.csv\n",
            "- csv_files/risk_reward_by_sentiment.csv\n",
            "- csv_files/pnl_distribution_stats.csv\n",
            "✅ Done. Figures in outputs/, CSVs in csv_files/, report in ds_report.pdf\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Extended Colab Notebook - Web3 Trading Team (Deep Insights)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams.update({\"figure.dpi\": 120})\n",
        "\n",
        "# Create required directories\n",
        "for d in [\"csv_files\", \"outputs\"]:\n",
        "    Path(d).mkdir(exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 1. Load Data\n",
        "# ============================================================\n",
        "trader_data_url = \"https://drive.google.com/uc?id=1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\"\n",
        "sentiment_data_url = \"https://drive.google.com/uc?id=1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\"\n",
        "\n",
        "print(\"Loading CSVs...\")\n",
        "trader_df = pd.read_csv(trader_data_url, low_memory=False)\n",
        "sentiment_df = pd.read_csv(sentiment_data_url, low_memory=False)\n",
        "print(\"Loaded.\")\n",
        "\n",
        "print(\"Trader shape:\", trader_df.shape)\n",
        "print(\"Trader cols:\", trader_df.columns.tolist())\n",
        "print(\"Sentiment shape:\", sentiment_df.shape)\n",
        "print(\"Sentiment cols:\", sentiment_df.columns.tolist())\n",
        "\n",
        "# ============================================================\n",
        "# 2. Timestamp Parsing\n",
        "# ============================================================\n",
        "def parse_maybe_unix(series):\n",
        "    if np.issubdtype(series.dtype, np.number):\n",
        "        try:\n",
        "            return pd.to_datetime(series, unit=\"ms\", errors=\"coerce\")\n",
        "        except:\n",
        "            return pd.to_datetime(series, unit=\"s\", errors=\"coerce\")\n",
        "    return pd.to_datetime(series, errors=\"coerce\")\n",
        "\n",
        "# Trader timestamps\n",
        "trader_df[\"ts_numeric\"] = parse_maybe_unix(trader_df.get(\"Timestamp\"))\n",
        "trader_df[\"ts_ist\"] = pd.to_datetime(trader_df.get(\"Timestamp IST\"), dayfirst=True, errors=\"coerce\")\n",
        "trader_df[\"trade_time\"] = trader_df[\"ts_ist\"].combine_first(trader_df[\"ts_numeric\"])\n",
        "trader_df[\"trade_date\"] = trader_df[\"trade_time\"].dt.date\n",
        "\n",
        "# Sentiment timestamps\n",
        "sentiment_df[\"sent_date\"] = pd.to_datetime(sentiment_df[\"date\"], errors=\"coerce\").dt.date\n",
        "sentiment_df[\"sent_unix\"] = parse_maybe_unix(sentiment_df[\"timestamp\"])\n",
        "sentiment_df[\"sent_date_unix\"] = sentiment_df[\"sent_unix\"].dt.date\n",
        "sentiment_df[\"date_final\"] = sentiment_df[\"sent_date\"].fillna(sentiment_df[\"sent_date_unix\"])\n",
        "\n",
        "sentiment_df[\"classification\"] = sentiment_df[\"classification\"].astype(str).str.strip().str.title()\n",
        "sentiment_df[\"sent_value\"] = pd.to_numeric(sentiment_df[\"value\"], errors=\"coerce\")\n",
        "\n",
        "sentiment_clean = sentiment_df[[\"date_final\", \"classification\", \"sent_value\"]].dropna().rename(columns={\"date_final\":\"date\"})\n",
        "sentiment_clean[\"date\"] = pd.to_datetime(sentiment_clean[\"date\"]).dt.date\n",
        "\n",
        "print(\"Sentiment unique classes:\", sentiment_clean[\"classification\"].unique())\n",
        "\n",
        "# ============================================================\n",
        "# 3. Merge\n",
        "# ============================================================\n",
        "merged = trader_df.merge(sentiment_clean, left_on=\"trade_date\", right_on=\"date\", how=\"left\")\n",
        "\n",
        "# Fill missing sentiment by forward-fill\n",
        "daily_sent = sentiment_clean.set_index(\"date\").sort_index()\n",
        "all_dates = pd.date_range(trader_df[\"trade_date\"].min(), trader_df[\"trade_date\"].max())\n",
        "daily_sent_full = daily_sent.reindex(all_dates.date).ffill().reset_index().rename(columns={\"index\":\"date\"})\n",
        "merged = merged.merge(daily_sent_full, on=\"date\", how=\"left\", suffixes=(\"\",\"_ffill\"))\n",
        "merged[\"classification\"] = merged[\"classification\"].fillna(merged.get(\"classification_ffill\"))\n",
        "merged[\"sent_value\"] = merged[\"sent_value\"].fillna(merged.get(\"sent_value_ffill\"))\n",
        "merged.drop([c for c in merged.columns if c.endswith(\"_ffill\")], axis=1, inplace=True)\n",
        "\n",
        "print(\"After merge, sentiment coverage:\", merged[\"classification\"].notna().mean())\n",
        "\n",
        "# ============================================================\n",
        "# 4. Normalize & Detect Columns\n",
        "# ============================================================\n",
        "merged.columns = [c.lower().replace(\" \", \"_\") for c in merged.columns]\n",
        "\n",
        "def find_col(df, keywords):\n",
        "    for c in df.columns:\n",
        "        if all(k in c for k in keywords):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "col_coin = find_col(merged, [\"coin\"]) or \"coin\"\n",
        "col_account = find_col(merged, [\"account\"]) or \"account\"\n",
        "col_pnl = find_col(merged, [\"pnl\"]) or \"closed_pnl\"\n",
        "col_size_usd = find_col(merged, [\"size\",\"usd\"]) or \"size_usd\"\n",
        "col_side = find_col(merged, [\"side\"]) or \"side\"\n",
        "\n",
        "merged[\"closed_pnl\"] = pd.to_numeric(merged[col_pnl], errors=\"coerce\")\n",
        "merged[\"size_usd\"] = pd.to_numeric(merged[col_size_usd], errors=\"coerce\")\n",
        "merged[\"side_norm\"] = merged[col_side].astype(str).str.upper()\n",
        "merged[\"profitable\"] = merged[\"closed_pnl\"] > 0\n",
        "merged[\"hour\"] = merged[\"trade_time\"].dt.hour\n",
        "\n",
        "print(\"Detected cols:\", col_coin, col_account, col_pnl, col_size_usd, col_side)\n",
        "\n",
        "# ============================================================\n",
        "# 5. Analysis & Plots\n",
        "# ============================================================\n",
        "def save_fig(fig, name):\n",
        "    out = Path(\"outputs\")/name\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    return out\n",
        "\n",
        "fig_paths = []\n",
        "\n",
        "# 5.1 PnL distribution\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "sns.boxplot(data=merged, x=\"classification\", y=\"closed_pnl\")\n",
        "plt.title(\"PnL Distribution by Sentiment\")\n",
        "fig_paths.append(save_fig(fig, \"pnl_distribution.png\"))\n",
        "\n",
        "# 5.2 Win rate\n",
        "win_rate = merged.groupby(\"classification\")[\"profitable\"].mean()*100\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=win_rate.index, y=win_rate.values)\n",
        "plt.title(\"Win Rate by Sentiment\")\n",
        "fig_paths.append(save_fig(fig, \"win_rate.png\"))\n",
        "\n",
        "# 5.3 Trade volume\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "vol = merged.groupby(\"classification\")[\"size_usd\"].sum()\n",
        "sns.barplot(x=vol.index, y=vol.values)\n",
        "plt.title(\"Total Volume by Sentiment\")\n",
        "fig_paths.append(save_fig(fig, \"volume.png\"))\n",
        "\n",
        "# 5.4 Hourly volume\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "hourly = merged.groupby([\"hour\",\"classification\"])[\"size_usd\"].sum().reset_index()\n",
        "sns.lineplot(data=hourly, x=\"hour\", y=\"size_usd\", hue=\"classification\")\n",
        "plt.title(\"Hourly Trade Volume by Sentiment\")\n",
        "fig_paths.append(save_fig(fig, \"hourly_volume.png\"))\n",
        "\n",
        "# 5.5 Volatility of PnL by sentiment\n",
        "pnl_vol = merged.groupby(\"classification\")[\"closed_pnl\"].std().sort_values(ascending=False)\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=pnl_vol.index, y=pnl_vol.values)\n",
        "plt.title(\"PnL Volatility by Sentiment (Std Dev)\")\n",
        "fig_paths.append(save_fig(fig, \"pnl_volatility.png\"))\n",
        "\n",
        "# 5.6 Next-day sentiment effect\n",
        "daily_pnl = merged.groupby(\"trade_date\")[\"closed_pnl\"].mean().reset_index()\n",
        "daily_pnl = daily_pnl.merge(sentiment_clean, left_on=\"trade_date\", right_on=\"date\", how=\"left\")\n",
        "daily_pnl[\"prev_sentiment\"] = daily_pnl[\"classification\"].shift(1)\n",
        "lag_summary = daily_pnl.groupby(\"prev_sentiment\")[\"closed_pnl\"].mean().dropna()\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=lag_summary.index, y=lag_summary.values)\n",
        "plt.title(\"Avg Daily PnL by Previous-Day Sentiment\")\n",
        "fig_paths.append(save_fig(fig, \"lagged_pnl.png\"))\n",
        "\n",
        "# 5.7 Average trade size by sentiment\n",
        "avg_size = merged.groupby(\"classification\")[\"size_usd\"].mean()\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=avg_size.index, y=avg_size.values)\n",
        "plt.title(\"Average Trade Size by Sentiment\")\n",
        "fig_paths.append(save_fig(fig, \"avg_trade_size.png\"))\n",
        "\n",
        "# 5.8 Skewness & kurtosis of PnL by sentiment\n",
        "pnl_stats = merged.groupby(\"classification\")[\"closed_pnl\"].agg([skew, kurtosis])\n",
        "pnl_stats.to_csv(\"csv_files/pnl_distribution_stats.csv\")\n",
        "\n",
        "# 5.9 Coin × Sentiment heatmap\n",
        "coin_sentiment_pnl = merged.groupby([col_coin,\"classification\"])[\"closed_pnl\"].mean().unstack()\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "sns.heatmap(coin_sentiment_pnl.fillna(0), cmap=\"RdYlGn\", center=0, annot=False)\n",
        "plt.title(\"Coin vs Sentiment: Avg Closed PnL\")\n",
        "fig_paths.append(save_fig(fig, \"coin_sentiment_heatmap.png\"))\n",
        "\n",
        "# 5.10 Hourly PnL by sentiment\n",
        "hourly_pnl = merged.groupby([\"hour\",\"classification\"])[\"closed_pnl\"].mean().reset_index()\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "sns.lineplot(data=hourly_pnl, x=\"hour\", y=\"closed_pnl\", hue=\"classification\")\n",
        "plt.title(\"Hourly Avg PnL by Sentiment\")\n",
        "fig_paths.append(save_fig(fig, \"hourly_pnl.png\"))\n",
        "\n",
        "# 5.11 Account sentiment profiles\n",
        "acct_sentiment = merged.groupby([col_account,\"classification\"])[\"closed_pnl\"].mean().unstack()\n",
        "acct_sentiment.to_csv(\"csv_files/account_sentiment_profiles.csv\")\n",
        "\n",
        "# 5.12 Accounts summary\n",
        "acct_stats = merged.groupby(col_account).agg(total_pnl=(\"closed_pnl\",\"sum\"),\n",
        "                                            avg_pnl=(\"closed_pnl\",\"mean\"),\n",
        "                                            trades=(\"closed_pnl\",\"count\"),\n",
        "                                            win_rate=(\"profitable\",\"mean\"))\n",
        "acct_stats.to_csv(\"csv_files/account_stats.csv\")\n",
        "\n",
        "# 5.13 Top accounts\n",
        "top_accts = acct_stats.sort_values(\"total_pnl\", ascending=False).head(10)\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=top_accts[\"total_pnl\"].values, y=top_accts.index)\n",
        "plt.title(\"Top 10 Accounts by PnL\")\n",
        "fig_paths.append(save_fig(fig, \"top_accounts.png\"))\n",
        "\n",
        "# ============================================================\n",
        "# 6. Export CSV Outputs\n",
        "# ============================================================\n",
        "merged.to_csv(\"csv_files/merged_trader_sentiment_processed.csv\", index=False)\n",
        "win_rate.round(2).to_csv(\"csv_files/win_rate_by_sentiment.csv\")\n",
        "vol.to_csv(\"csv_files/volume_by_sentiment.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. Report\n",
        "# ============================================================\n",
        "with PdfPages(\"ds_report.pdf\") as pdf:\n",
        "    fig = plt.figure(figsize=(11,8.5))\n",
        "    plt.axis(\"off\")\n",
        "    plt.text(0.5,0.6,\"Web3 Trading Team - Data Science Assignment\",ha=\"center\",fontsize=18)\n",
        "    plt.text(0.5,0.45,\"Candidate: ds_<your_name>\",ha=\"center\",fontsize=14)\n",
        "    pdf.savefig(fig); plt.close(fig)\n",
        "\n",
        "    for fp in fig_paths:\n",
        "        img = plt.imread(fp)\n",
        "        fig = plt.figure(figsize=(11,8.5))\n",
        "        plt.imshow(img); plt.axis(\"off\")\n",
        "        pdf.savefig(fig); plt.close(fig)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 9. Package all results into a zip for download\n",
        "# ============================================================\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "out_zip = \"ds_submission.zip\"\n",
        "\n",
        "# Add everything into the zip\n",
        "with zipfile.ZipFile(out_zip, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    # Report\n",
        "    if Path(\"ds_report.pdf\").exists():\n",
        "        zf.write(\"ds_report.pdf\")\n",
        "    # Folders\n",
        "    for folder in [\"outputs\", \"csv_files\"]:\n",
        "        if Path(folder).exists():\n",
        "            for file in Path(folder).rglob(\"*\"):\n",
        "                zf.write(file)\n",
        "\n",
        "print(f\"✅ Created {out_zip} with all results\")\n",
        "\n",
        "# Trigger download\n",
        "files.download(out_zip)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e9OAv3EdJD7v",
        "outputId": "52476430-49d8-457b-c38f-bb3e04a1faab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created ds_submission.zip with all results\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d0ebcd49-c88e-4550-9685-61d2fdf5d3f4\", \"ds_submission.zip\", 11624957)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}